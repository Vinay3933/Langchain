{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here's one:\\n\\nWhy don't eggs tell jokes?\\n\\n(Wait for it...)\\n\\nBecause they'd crack each other up!\\n\\nHope that made you smile! Do you want to hear another one?\" response_metadata={'model': 'llama3', 'created_at': '2024-06-05T06:02:20.115529Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1822168541, 'load_duration': 1097389958, 'prompt_eval_count': 13, 'prompt_eval_duration': 87941000, 'eval_count': 39, 'eval_duration': 635511000} id='run-cee0b5cb-7486-48ec-9a90-769e581617ef-0'\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is Task Decomposition?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Task Decomposition?',\n",
       " 'context': [Document(page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       "  Document(page_content='They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       "  Document(page_content='Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       "  Document(page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})],\n",
       " 'answer': \"Task decomposition refers to the process of breaking down complex tasks into smaller, more manageable subtasks that can be executed individually or in parallel. This approach aims to simplify the original task by identifying its constituent parts and tackling them one by one, reducing the overall complexity and increasing the likelihood of success.\\n\\nIn the context of AI assistants like myself, task decomposition is crucial for handling user requests efficiently. By decomposing tasks into smaller components, we can:\\n\\n1. Better understand the user's intent and requirements.\\n2. Identify dependencies between subtasks and plan accordingly.\\n3. Distribute workload among multiple agents or systems, if needed.\\n4. Improve error detection and correction by focusing on individual subtasks.\\n\\nTask decomposition is a fundamental concept in AI research and development, particularly in areas like natural language processing, computer vision, and robotics. By applying this technique, we can design more effective and robust AI systems that can handle complex tasks with greater ease and accuracy.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several common ways to perform task decomposition:\n",
      "\n",
      "1. **Divide-and-Conquer**: Break down the task into smaller subtasks that can be solved independently. This approach is effective for tasks with multiple components or steps.\n",
      "2. **Goal-Task-Step (GTS)**: Identify the goal, then break it down into specific tasks, and finally decompose each task into individual steps.\n",
      "3. **Objectives-Operations-Outcomes (OOO)**: Define the objectives, identify the operations required to achieve them, and determine the outcomes or results expected.\n",
      "4. **Decomposition by Function**: Identify the functional components of the task and break it down accordingly. For example, if the task involves data processing, you might decompose it into data cleaning, transformation, and analysis steps.\n",
      "5. **Hierarchical Decomposition**: Break down the task into smaller subtasks that are further decomposed until you reach the individual steps required to complete the task.\n",
      "\n",
      "These approaches can be applied in various domains, including software development, project management, and AI-assisted decision-making.\n"
     ]
    }
   ],
   "source": [
    "## Manually updating Chat history\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is Task Decomposition?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "second_question = \"What are common ways of doing it?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Auto update chat history\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down complex tasks into smaller, more manageable subtasks that can be solved individually or in parallel. This approach helps to simplify the task, reduce its complexity, and make it easier to solve.\\n\\nIn the context of AI-powered assistants like myself, task decomposition allows us to:\\n\\n1. Identify the dependencies between subtasks\\n2. Focus on specific skills or knowledge required for each subtask\\n3. Reuse solutions or partial solutions from previous tasks\\n\\nBy decomposing a complex task into smaller parts, we can leverage our abilities to solve each subtask and then combine the results to complete the original task.\\n\\nTask decomposition is particularly useful when dealing with tasks that require:\\n\\n1. Domain-specific knowledge or expertise\\n2. Complex decision-making or problem-solving\\n3. Integration of multiple skills or tools\\n\\nIn your case, the experiment on fine-tuning LLMs for arithmetic operations is an excellent example of task decomposition!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is Task Decomposition?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are several approaches to task decomposition, and I'll outline some common ones:\\n\\n1. **Divide and Conquer**: Break down the complex task into smaller, more manageable subtasks that can be solved individually. This approach is effective when dealing with tasks that have a clear hierarchical structure or can be partitioned based on specific features.\\n2. **Top-Down Approach**: Start by identifying the overall goal or objective of the task and then work your way down to identify the necessary steps or subtasks required to achieve it. This approach helps in capturing the broader context and ensuring that all relevant aspects are considered.\\n3. **Bottom-Up Approach**: Begin with individual, smaller tasks or subtasks that can be solved independently, and then combine the results to form the overall solution. This approach is useful when dealing with tasks that have many local optima or where small changes can have significant effects.\\n4. **Hybrid Approach**: Combine elements of both top-down and bottom-up approaches by starting with a high-level overview of the task and then focusing on individual subtasks. This hybrid approach allows for balancing the benefits of both methods.\\n5. **Pattern-Based Decomposition**: Identify common patterns or structures within the task and use them as a basis for decomposition. For example, if you're working on a text classification problem, you might identify patterns related to specific keywords, entities, or sentiment.\\n6. **Task Graphing**: Represent the complex task as a graph, where nodes represent subtasks, and edges represent dependencies between them. This visual approach can help in identifying relationships, identifying bottlenecks, and optimizing the decomposition process.\\n\\nThese are just a few common ways of doing task decomposition. The key is to choose an approach that best fits the specific task, your skills, and the available resources.\\n\\nNow, if you'd like to know more about fine-tuning LLMs for arithmetic operations or have any further questions, feel free to ask!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are common ways of doing it?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Task Decomposition?'),\n",
       " AIMessage(content='Task decomposition is the process of breaking down complex tasks into smaller, more manageable subtasks that can be solved individually or in parallel. This approach helps to simplify the task, reduce its complexity, and make it easier to solve.\\n\\nIn the context of AI-powered assistants like myself, task decomposition allows us to:\\n\\n1. Identify the dependencies between subtasks\\n2. Focus on specific skills or knowledge required for each subtask\\n3. Reuse solutions or partial solutions from previous tasks\\n\\nBy decomposing a complex task into smaller parts, we can leverage our abilities to solve each subtask and then combine the results to complete the original task.\\n\\nTask decomposition is particularly useful when dealing with tasks that require:\\n\\n1. Domain-specific knowledge or expertise\\n2. Complex decision-making or problem-solving\\n3. Integration of multiple skills or tools\\n\\nIn your case, the experiment on fine-tuning LLMs for arithmetic operations is an excellent example of task decomposition!'),\n",
       " HumanMessage(content='What are common ways of doing it?'),\n",
       " AIMessage(content=\"There are several approaches to task decomposition, and I'll outline some common ones:\\n\\n1. **Divide and Conquer**: Break down the complex task into smaller, more manageable subtasks that can be solved individually. This approach is effective when dealing with tasks that have a clear hierarchical structure or can be partitioned based on specific features.\\n2. **Top-Down Approach**: Start by identifying the overall goal or objective of the task and then work your way down to identify the necessary steps or subtasks required to achieve it. This approach helps in capturing the broader context and ensuring that all relevant aspects are considered.\\n3. **Bottom-Up Approach**: Begin with individual, smaller tasks or subtasks that can be solved independently, and then combine the results to form the overall solution. This approach is useful when dealing with tasks that have many local optima or where small changes can have significant effects.\\n4. **Hybrid Approach**: Combine elements of both top-down and bottom-up approaches by starting with a high-level overview of the task and then focusing on individual subtasks. This hybrid approach allows for balancing the benefits of both methods.\\n5. **Pattern-Based Decomposition**: Identify common patterns or structures within the task and use them as a basis for decomposition. For example, if you're working on a text classification problem, you might identify patterns related to specific keywords, entities, or sentiment.\\n6. **Task Graphing**: Represent the complex task as a graph, where nodes represent subtasks, and edges represent dependencies between them. This visual approach can help in identifying relationships, identifying bottlenecks, and optimizing the decomposition process.\\n\\nThese are just a few common ways of doing task decomposition. The key is to choose an approach that best fits the specific task, your skills, and the available resources.\\n\\nNow, if you'd like to know more about fine-tuning LLMs for arithmetic operations or have any further questions, feel free to ask!\")]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['abc123'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

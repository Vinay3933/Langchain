{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "from langchain_community.chat_models import ChatLlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your model weights\n",
    "model_dir = \"/Users/vinaytanwer/Desktop/Projects/Chatbots/LLM_checkpoints/NousResearch\"\n",
    "model_name = \"Hermes-2-Pro-Llama-3-8B-Q8_0.gguf\"\n",
    "# model_name = \"Hermes-2-Theta-Llama-3-70B-Q5_K_M.gguf\"\n",
    "local_model = os.path.join(model_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatLlamaCpp(\n",
    "    temperature=0,\n",
    "    model_path=local_model,\n",
    "    n_ctx=10000,\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=300,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    # max_tokens=512,\n",
    "    # n_threads=multiprocessing.cpu_count() - 1,\n",
    "    # callback_manager=callback_manager,\n",
    "    # repeat_penalty=0.5,\n",
    "    # top_p=0.5,\n",
    "    f16_kv=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": {\n",
      "    \"first\": \"John\",\n",
      "    \"last\": \"Doe\"\n",
      "  },\n",
      "  \"age\": 35,\n",
      "  \"gender\": \"male\",\n",
      "  \"address\": {\n",
      "    \"street\": \"123 Main Street\",\n",
      "    \"city\": \"New York\",\n",
      "    \"state\": \"NY\",\n",
      "    \"zip\": \"10001\"\n",
      "  },\n",
      "  \"phone_number\": \"+1 (234) 567-8901\",\n",
      "  \"email\": \"john.doe@example.com\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Describe a person in JSON format:\")\n",
    "# print(response, '\\n')\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime programmer."
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "# ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime programmer.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मुझे प्रोग्रामिंग पसंद है।"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Hindi\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मुझे प्रोग्रामिंग पसंद है।\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
    "    unit: str = Field(enum=[\"celsius\", \"fahrenheit\"])\n",
    "\n",
    "\n",
    "@tool(\"get_current_weather\", args_schema=WeatherInput)\n",
    "def get_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    return f\"Now the weather in {location} is 22 {unit}\"\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(\n",
    "    tools=[get_weather],   \n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"\"\"You are a helpful assistant.\n",
    "#             Apart from your own knowledge base, following tools are binded to you using bind_tool method: \n",
    "#             1) get_current_weather - Get the current weather in a given location\n",
    "\n",
    "#             Delegate the task to the tool regarding weather information. Do not make any wild guesses.\n",
    "#             Say \"I don't know\" if neither you nor the tools can answer the user query\n",
    "#             \"\"\"\n",
    "#         ),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm_with_tools.invoke(\n",
    "    \"what is the weather in New Delhi in celsius \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_current_weather',\n",
       "  'args': {'location': 'New Delhi', 'unit': 'celsius'},\n",
       "  'id': 'call__0_get_current_weather_cmpl-04a97cf4-2517-415c-b72b-a5037f4b6087'}]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{ \"location\": \"New Delhi\", \"unit\": \"celsius\"}'}, 'tool_calls': [{'id': 'call__0_get_current_weather_cmpl-04a97cf4-2517-415c-b72b-a5037f4b6087', 'type': 'function', 'function': {'name': 'get_current_weather', 'arguments': '{ \"location\": \"New Delhi\", \"unit\": \"celsius\"}'}}]}, response_metadata={'token_usage': {'prompt_tokens': 20, 'completion_tokens': 15, 'total_tokens': 35}, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-193da2a5-8b4e-47c2-a217-2a5db65b1036-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'New Delhi', 'unit': 'celsius'}, 'id': 'call__0_get_current_weather_cmpl-04a97cf4-2517-415c-b72b-a5037f4b6087'}])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_magic_function',\n",
       "  'args': {'magic_function_input': 3},\n",
       "  'id': 'call__0_get_magic_function_cmpl-4597a1db-3ede-4916-9ced-b015cc18e6cc'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MagicFunctionInput(BaseModel):\n",
    "    magic_function_input: int = Field(description=\"The input value for magic function\")\n",
    "\n",
    "\n",
    "@tool(\"get_magic_function\", args_schema=MagicFunctionInput)\n",
    "def magic_function(magic_function_input: int):\n",
    "    \"\"\"Get the value of magic function for an input.\"\"\"\n",
    "    return magic_function_input + 2\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(\n",
    "    tools=[magic_function],\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_magic_function\"}},\n",
    ")\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(\n",
    "    \"What is magic function of 3?\",\n",
    ")\n",
    "\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't Batman and Robin ever go on vacation together?\",\n",
       " 'punchline': \"Because they'd be gone for R&R!\"}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"A setup to a joke and the punchline.\"\"\"\n",
    "\n",
    "    setup: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "dict_schema = convert_to_openai_tool(Joke)\n",
    "structured_llm = llm.with_structured_output(dict_schema)\n",
    "result = structured_llm.invoke(\"Tell me a joke about batman\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did Batman refuse to join the Justice League? Because he couldn't find any Robin in it."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"Tell me a joke about Justice League characters. Keep the response concise\"):\n",
    "    # print(chunk.content, flush=True, end=\"\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binding Multiple tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool(\"get_magic_function\", args_schema=MagicFunctionInput)\n",
    "def fn_magic_function(magic_function_input: int):\n",
    "    \"\"\"Get the value of magic function for an input.\"\"\"\n",
    "    return magic_function_input + 2\n",
    "\n",
    "# @tool(\"get_current_weather\", args_schema=WeatherInput)\n",
    "def fn_get_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    return f\"Now the weather in {location} is 22 {unit}\"\n",
    "\n",
    "llm_with_tools = llm.bind_tools(\n",
    "    tools=[fn_magic_function, fn_get_weather],\n",
    "    # tool_choice= {\"type\": \"function\", \"function\": {\"name\": \"fn_get_weather\"}}\n",
    "    # tool_choice= {\"type\": \"auto\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To provide you with an accurate and up-to-date answer, I would need to access real-time data from a reliable source. Please allow me to check the current temperature in Ho Chi Minh City (HCMC) for you. \n",
      "\n",
      "Please wait for a moment while I gather this information for you."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To provide you with an accurate and up-to-date answer, I would need to access real-time data from a reliable source. Please allow me to check the current temperature in Ho Chi Minh City (HCMC) for you. \\n\\nPlease wait for a moment while I gather this information for you.', response_metadata={'finish_reason': 'stop'}, id='run-a925c698-58c0-4422-8956-0940c6717e9e-0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm_with_tools.invoke(\n",
    "    \"what is the current weather in HCMC in celsius\",\n",
    ")\n",
    "\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherInput(BaseModel):\n",
    "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
    "    unit: str = Field(enum=[\"celsius\", \"fahrenheit\"])\n",
    "\n",
    "class MagicFunctionInput(BaseModel):\n",
    "    magic_function_input: int = Field(description=\"The input value for magic function\")\n",
    "\n",
    "@tool(\"get_current_weather\", args_schema=WeatherInput)\n",
    "# @tool\n",
    "def fn_get_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    return f\"Now the weather in {location} is 22 {unit}\"\n",
    "\n",
    "@tool(\"get_magic_function\", args_schema=MagicFunctionInput)\n",
    "def fn_magic_function(magic_function_input: int):\n",
    "    \"\"\"Get the value of magic function for an input.\"\"\"\n",
    "    return magic_function_input + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_get_weather.__dict__\n",
    "# fn_get_weather.args_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_current_weather', 'description': 'Get the current weather in a given location', 'parameters': {'title': 'WeatherInput', 'type': 'object', 'properties': {'location': {'title': 'Location', 'description': 'The city and state, e.g. San Francisco, CA', 'type': 'string'}, 'unit': {'title': 'Unit', 'enum': ['celsius', 'fahrenheit'], 'type': 'string'}}, 'required': ['location', 'unit']}}, {'name': 'get_magic_function', 'description': 'Get the value of magic function for an input.', 'parameters': {'title': 'MagicFunctionInput', 'type': 'object', 'properties': {'magic_function_input': {'title': 'Magic Function Input', 'description': 'The input value for magic function', 'type': 'integer'}}, 'required': ['magic_function_input']}}]\n"
     ]
    }
   ],
   "source": [
    "def get_function_signature(tools):\n",
    "    signature_list = []\n",
    "    for tool in tools:\n",
    "        signature = {}\n",
    "        signature[\"name\"] = tool.name\n",
    "        signature[\"description\"] = tool.description\n",
    "        signature[\"parameters\"] = tool.args_schema.schema()\n",
    "        signature_list.append(signature)\n",
    "\n",
    "    return signature_list\n",
    "\n",
    "tools = [fn_get_weather, fn_magic_function]\n",
    "tools_signature = get_function_signature(tools)\n",
    "\n",
    "print(f\"{tools_signature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(tools_signature[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import XMLOutputParser\n",
    "from langchain_core.output_parsers.json import JsonOutputParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate(\n",
    "# template = \"\"\"\n",
    "# <|im_start|>system\n",
    "# You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. \n",
    "# You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. \n",
    "# Here are the available tools: \n",
    "# <tools>\n",
    "# {signatures}\n",
    "# </tools>\n",
    "# For each function call return a preamble statement followed by json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "# <tool_call>{{'arguments': <args-dict>, 'name: <function-name>}}</tool_call>\n",
    "# <|im_end|>\n",
    "# <|im_start|>user\n",
    "# {query}\n",
    "# <|im_end|>\n",
    "# <im_start|>assistant\n",
    "# \"\"\",\n",
    "# input_variables=['signatures', 'query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "template = \"\"\"\n",
    "<|im_start|>system\n",
    "You are a helpful assistant. You are also provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query if you are unsure about the answer. Don't make assumptions about what values to plug into functions. \n",
    "Here are the available tools: \n",
    "<tools>\n",
    "{signatures}\n",
    "</tools>\n",
    "If you do not require function call to answer user query, respond in string format.\n",
    "In case of a function call, do not include a preamble statement, only return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>{{'arguments': <args-dict>, 'name: <function-name>}}</tool_call>\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{query}\n",
    "<|im_end|>\n",
    "\"\"\",\n",
    "input_variables=['signatures', 'query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prompt.invoke({'signatures':f\"{tools_signature}\", \"query\":\"What is the current weather in New Delhi in celsius\"}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<tool_call>{'arguments': {'location': 'New Delhi', 'unit': 'celsius'}, 'name': 'fn_get_weather'}</tool_call>\", response_metadata={'finish_reason': 'stop'}, id='run-0a16b8c4-2cce-469f-849a-5456792eecd1-0')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm.bind_tools(tools)\n",
    "response = chain.invoke(\n",
    "    {'signatures':f\"{tools_signature}\",\n",
    "     \"query\":\"What is the current weather in New Delhi in celsius\",\n",
    "    #  \"query\":\"What is the magic function of 10\",\n",
    "    #  \"query\":\"Tell me a joke above batman\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'location': 'New Delhi', 'unit': 'celsius'},\n",
       " 'name': 'fn_get_weather'}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree import ElementTree as et\n",
    "# import json\n",
    "import ast\n",
    "\n",
    "tool_call = et.fromstring(response.content)\n",
    "tool_call = ast.literal_eval(tool_call.text)\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now the weather in New Delhi is 22 celsius'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response = fn_get_weather.invoke(tool_call['arguments'])\n",
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current weather in New Delhi is 22 degrees Celsius.', response_metadata={'finish_reason': 'stop'}, id='run-d628d8fc-2fad-4300-9b2c-5978bfb21833-0')"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "template = \"\"\"\n",
    "<|im_start|>system\n",
    "You are a helpful assistant. You are also provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query if you are unsure about the answer. Don't make assumptions about what values to plug into functions.\n",
    "Wait for the tool to respond to return the final answer in case of a tool call. Tool response would be provided in <tool_response></tool_response> XML tags.\n",
    "Here are the available tools: \n",
    "<tools>\n",
    "{signatures}\n",
    "</tools>\n",
    "If you do not require function call to answer user query, respond in string format.\n",
    "In case of a function call, do not include a preamble statement, only return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>{{\"arguments\": <args-dict>, \"name\": <function-name>}}</tool_call>\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{query}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<tool_call>{{'arguments': {{'location': 'New Delhi', 'unit': 'celsius'}}, 'name': 'fn_get_weather'}}</tool_call>\n",
    "<|im_end|>\n",
    "<|im_start|>tool\n",
    "<tool_response>{{'content': 'Now the weather in New Delhi is 22 celsius', 'name': 'fn_get_weather'}}</tool_response>\n",
    "<|im_end|>\n",
    "\"\"\",\n",
    "input_variables=['signatures', 'query'])\n",
    "\n",
    "chain = prompt | llm.bind_tools(tools)\n",
    "response = chain.invoke(\n",
    "    {'signatures':f\"{tools_signature}\",\n",
    "     \"query\":\"What is the current weather in New Delhi in celsius\",\n",
    "    #  \"query\":\"What is the magic function of 10\",\n",
    "    #  \"query\":\"Tell me a joke above batman\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<tool_call>{\"arguments\": {\"location\": \"New Delhi\", \"unit\": \"celsius\"}, \"name\": \"get_current_weather\"}</tool_call>', response_metadata={'finish_reason': 'stop'}, id='run-34b68570-b3ad-4f79-b061-522d1ad6f538-0')"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a helpful assistant. You are also provided with function signatures within <tools></tools> XML tags.\n",
    "        You may call one or more functions to assist with the user query if you are unsure about the answer. Don't make assumptions about what values to plug into functions.\n",
    "        Wait for the tool to respond to return the final answer in case of a tool call. Tool response would be provided in <tool_response></tool_response> XML tags.\n",
    "        Here are the available tools: \n",
    "        <tools>\n",
    "        {signatures}\n",
    "        </tools>\n",
    "        If you do not require function call to answer user query, respond in string format.\n",
    "        In case of a function call, do not include a preamble statement, only return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "        <tool_call>{{\"arguments\": <args-dict>, \"name\": <function-name>}}</tool_call>\"\"\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "    # (\"assistant\", \"<tool_call>{{'arguments': {{'location': 'New Delhi', 'unit': 'celsius'}}, 'name': 'fn_get_weather'}}</tool_call>\"),\n",
    "    # (\"assistant\",\"<tool_response>{{'content': 'Now the weather in New Delhi is 22 celsius', 'name': 'fn_get_weather'}}</tool_response>\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm.bind_tools(tools)\n",
    "response = chain.invoke(\n",
    "    {'signatures':f\"{tools_signature}\",\n",
    "     \"query\":\"What is the current weather in New Delhi in celsius\",\n",
    "    #  \"query\":\"What is the magic function of 10\",\n",
    "    #  \"query\":\"Tell me a joke above batman\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'51b82461-6bc7-4048-abae-54080d7c2eb1'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant. You also have access to additional functions (tools) to assist with user queries. Function signatures are provided within <tools></tools> XML tags.\\n        You may call one or more functions to assist with the user query if you are unsure about the answer. Don\\'t make assumptions about what values to plug into functions.\\n        When you make a tool call, wait for the tool to respond to generate the final answer. Tool response would be provided in <tool_response></tool_response> XML tags.\\n        Here are the available tools: \\n        <tools>[{\\'name\\': \\'get_current_weather\\', \\'description\\': \\'Get the current weather in a given location\\', \\'parameters\\': {\\'title\\': \\'WeatherInput\\', \\'type\\': \\'object\\', \\'properties\\': {\\'location\\': {\\'title\\': \\'Location\\', \\'description\\': \\'The city and state, e.g. San Francisco, CA\\', \\'type\\': \\'string\\'}, \\'unit\\': {\\'title\\': \\'Unit\\', \\'enum\\': [\\'celsius\\', \\'fahrenheit\\'], \\'type\\': \\'string\\'}}, \\'required\\': [\\'location\\', \\'unit\\']}}, {\\'name\\': \\'get_magic_function\\', \\'description\\': \\'Get the value of magic function for an input.\\', \\'parameters\\': {\\'title\\': \\'MagicFunctionInput\\', \\'type\\': \\'object\\', \\'properties\\': {\\'magic_function_input\\': {\\'title\\': \\'Magic Function Input\\', \\'description\\': \\'The input value for magic function\\', \\'type\\': \\'integer\\'}}, \\'required\\': [\\'magic_function_input\\']}}]</tools>\\n        If you do not require function call to answer user query, respond in string format.\\n        In case of a function call, do not include a preamble statement, only return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\\n        <tool_call>{\"arguments\": <args-dict>, \"name\": <function-name>}</tool_call>\\n    '), HumanMessage(content='What is the current weather in New Delhi in celsius'), AIMessage(content=\"<tool_call>{{'arguments': {{'location': 'New Delhi', 'unit': 'celsius'}}, 'name': 'fn_get_weather'}}</tool_call>\"), ToolMessage(content=\"<tool_response>{{'content': 'Now the weather in New Delhi is 22 celsius', 'name': 'fn_get_weather'}}</tool_response>\", tool_call_id='0cd6f2e7-f4ac-4052-a1c9-cca050c65aca')])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_id = f\"{uuid.uuid4()}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant. You also have access to additional functions (tools) to assist with user queries. Function signatures are provided within <tools></tools> XML tags.\n",
    "        You may call one or more functions to assist with the user query if you are unsure about the answer. Don't make assumptions about what values to plug into functions.\n",
    "        When you make a tool call, wait for the tool to respond to generate the final answer. Tool response would be provided in <tool_response></tool_response> XML tags.\n",
    "        Here are the available tools: \n",
    "        <tools>{signatures}</tools>\n",
    "        If you do not require function call to answer user query, respond in string format.\n",
    "        In case of a function call, do not include a preamble statement, only return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "        <tool_call>{{\"arguments\": <args-dict>, \"name\": <function-name>}}</tool_call>\n",
    "    \"\"\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "    AIMessage(content = \"<tool_call>{{'arguments': {{'location': 'New Delhi', 'unit': 'celsius'}}, 'name': 'fn_get_weather'}}</tool_call>\"),\n",
    "    ToolMessage(content = \"<tool_response>{{'content': 'Now the weather in New Delhi is 22 celsius', 'name': 'fn_get_weather'}}</tool_response>\", tool_call_id = tool_call_id)\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt #| llm.bind_tools(tools)\n",
    "response = chain.invoke(\n",
    "    {'signatures':f\"{tools_signature}\",\n",
    "     \"query\":\"What is the current weather in New Delhi in celsius\",\n",
    "    #  \"query\":\"What is the magic function of 10\",\n",
    "    #  \"query\":\"Tell me a joke above batman\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('location', <class 'str'>), ('unit', <class 'str'>)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fn_get_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    return f\"Now the weather in {location} is 22 {unit}\"\n",
    "\n",
    "fn_get_weather.__annotations__.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot = [\n",
    "    {\n",
    "        \"example\": \"```\\nSYSTEM: You are a helpful assistant who has access to functions. Use them if required\\n<tools>[\\n {\\n \\\"name\\\": \\\"calculate_distance\\\",\\n \\\"description\\\": \\\"Calculate the distance between two locations\\\",\\n \\\"parameters\\\": {\\n \\\"type\\\": \\\"object\\\",\\n \\\"properties\\\": {\\n \\\"origin\\\": {\\n \\\"type\\\": \\\"string\\\",\\n \\\"description\\\": \\\"The starting location\\\"\\n },\\n \\\"destination\\\": {\\n \\\"type\\\": \\\"string\\\",\\n \\\"description\\\": \\\"The destination location\\\"\\n },\\n \\\"mode\\\": {\\n \\\"type\\\": \\\"string\\\",\\n \\\"description\\\": \\\"The mode of transportation\\\"\\n }\\n },\\n \\\"required\\\": [\\n \\\"origin\\\",\\n \\\"destination\\\",\\n \\\"mode\\\"\\n ]\\n }\\n },\\n {\\n \\\"name\\\": \\\"generate_password\\\",\\n \\\"description\\\": \\\"Generate a random password\\\",\\n \\\"parameters\\\": {\\n \\\"type\\\": \\\"object\\\",\\n \\\"properties\\\": {\\n \\\"length\\\": {\\n \\\"type\\\": \\\"integer\\\",\\n \\\"description\\\": \\\"The length of the password\\\"\\n }\\n },\\n \\\"required\\\": [\\n \\\"length\\\"\\n ]\\n }\\n }\\n]\\n\\n</tools>\\nUSER: Hi, I need to know the distance from New York to Los Angeles by car.\\nASSISTANT:\\n<tool_call>\\n{\\\"arguments\\\": {\\\"origin\\\": \\\"New York\\\",\\n \\\"destination\\\": \\\"Los Angeles\\\", \\\"mode\\\": \\\"car\\\"}, \\\"name\\\": \\\"calculate_distance\\\"}\\n</tool_call>\\n```\\n\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"```\\nSYSTEM: You are a helpful assistant with access to functions. Use them if required\\n<tools>[\\n {\\n \\\"name\\\": \\\"calculate_distance\\\",\\n \\\"description\\\": \\\"Calculate the distance between two locations\\\",\\n \\\"parameters\\\": {\\n \\\"type\\\": \\\"object\\\",\\n \\\"properties\\\": {\\n \\\"origin\\\": {\\n \\\"type\\\": \\\"string\\\",\\n \\\"description\\\": \\\"The starting location\\\"\\n },\\n \\\"destination\\\": {\\n \\\"type\\\": \\\"string\\\",\\n \\\"description\\\": \\\"The destination location\\\"\\n },\\n \\\"mode\\\": {\\n \\\"type\\\": \\\"string\\\",\\n \\\"description\\\": \\\"The mode of transportation\\\"\\n }\\n },\\n \\\"required\\\": [\\n \\\"origin\\\",\\n \\\"destination\\\",\\n \\\"mode\\\"\\n ]\\n }\\n },\\n {\\n \\\"name\\\": \\\"generate_password\\\",\\n \\\"description\\\": \\\"Generate a random password\\\",\\n \\\"parameters\\\": {\\n \\\"type\\\": \\\"object\\\",\\n \\\"properties\\\": {\\n \\\"length\\\": {\\n \\\"type\\\": \\\"integer\\\",\\n \\\"description\\\": \\\"The length of the password\\\"\\n }\\n },\\n \\\"required\\\": [\\n \\\"length\\\"\\n ]\\n }\\n }\\n]\\n\\n</tools>\\nUSER: Can you help me generate a random password with a length of 8 characters?\\nASSISTANT:\\n<tool_call>\\n{\\\"arguments\\\": {\\\"length\\\": 8}, \\\"name\\\": \\\"generate_password\\\"}\\n</tool_call>\\n```\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "SYSTEM: You are a helpful assistant who has access to functions. Use them if required\n",
      "<tools>[\n",
      " {\n",
      " \"name\": \"calculate_distance\",\n",
      " \"description\": \"Calculate the distance between two locations\",\n",
      " \"parameters\": {\n",
      " \"type\": \"object\",\n",
      " \"properties\": {\n",
      " \"origin\": {\n",
      " \"type\": \"string\",\n",
      " \"description\": \"The starting location\"\n",
      " },\n",
      " \"destination\": {\n",
      " \"type\": \"string\",\n",
      " \"description\": \"The destination location\"\n",
      " },\n",
      " \"mode\": {\n",
      " \"type\": \"string\",\n",
      " \"description\": \"The mode of transportation\"\n",
      " }\n",
      " },\n",
      " \"required\": [\n",
      " \"origin\",\n",
      " \"destination\",\n",
      " \"mode\"\n",
      " ]\n",
      " }\n",
      " },\n",
      " {\n",
      " \"name\": \"generate_password\",\n",
      " \"description\": \"Generate a random password\",\n",
      " \"parameters\": {\n",
      " \"type\": \"object\",\n",
      " \"properties\": {\n",
      " \"length\": {\n",
      " \"type\": \"integer\",\n",
      " \"description\": \"The length of the password\"\n",
      " }\n",
      " },\n",
      " \"required\": [\n",
      " \"length\"\n",
      " ]\n",
      " }\n",
      " }\n",
      "]\n",
      "\n",
      "</tools>\n",
      "USER: Hi, I need to know the distance from New York to Los Angeles by car.\n",
      "ASSISTANT:\n",
      "<tool_call>\n",
      "{\"arguments\": {\"origin\": \"New York\",\n",
      " \"destination\": \"Los Angeles\", \"mode\": \"car\"}, \"name\": \"calculate_distance\"}\n",
      "</tool_call>\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(few_shot[0]['example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'tools' at 0x110603330>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "\n",
    "xmlstring = \"\"\"\n",
    "<tools>[\n",
    " {\n",
    " \"name\": \"calculate_distance\",\n",
    " \"description\": \"Calculate the distance between two locations\",\n",
    " \"parameters\": {\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"origin\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The starting location\"\n",
    " },\n",
    " \"destination\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The destination location\"\n",
    " },\n",
    " \"mode\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The mode of transportation\"\n",
    " }\n",
    " },\n",
    " \"required\": [\n",
    " \"origin\",\n",
    " \"destination\",\n",
    " \"mode\"\n",
    " ]\n",
    " }\n",
    " },\n",
    " {\n",
    " \"name\": \"generate_password\",\n",
    " \"description\": \"Generate a random password\",\n",
    " \"parameters\": {\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"length\": {\n",
    " \"type\": \"integer\",\n",
    " \"description\": \"The length of the password\"\n",
    " }\n",
    " },\n",
    " \"required\": [\n",
    " \"length\"\n",
    " ]\n",
    " }\n",
    " }\n",
    "]\n",
    "\n",
    "</tools>\n",
    "\"\"\"\n",
    "\n",
    "# xmlstring = few_shot[0]['example']\n",
    "\n",
    "# parser = ET.XMLParser(encoding=\"utf-8\")\n",
    "# output = ET.fromstring(xmlstring, parser=parser)\n",
    "\n",
    "output = ET.fromstring(xmlstring)\n",
    "\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"calculate_distance\",\n",
      "        \"description\": \"Calculate the distance between two locations\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"origin\": {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"The starting location\"\n",
      "                },\n",
      "                \"destination\": {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"The destination location\"\n",
      "                },\n",
      "                \"mode\": {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"The mode of transportation\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"origin\",\n",
      "                \"destination\",\n",
      "                \"mode\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"generate_password\",\n",
      "        \"description\": \"Generate a random password\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"length\": {\n",
      "                    \"type\": \"integer\",\n",
      "                    \"description\": \"The length of the password\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"length\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(output.text), indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"FunctionDefinition\",\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "        \"name\": {\n",
      "            \"title\": \"Name\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"description\": {\n",
      "            \"title\": \"Description\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"title\": \"Parameters\",\n",
      "            \"type\": \"object\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"name\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing import Optional, Dict\n",
    "\n",
    "class FunctionDefinition(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    parameters: Optional[Dict[str, object]] = None\n",
    "\n",
    "print(json.dumps(json.loads(FunctionDefinition.schema_json()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sample_fn_name',\n",
       " 'description': 'sample fn description',\n",
       " 'parameters': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defintn = FunctionDefinition(\n",
    "            name='sample_fn_name',\n",
    "            description='sample fn description',\n",
    "        )\n",
    "\n",
    "defintn.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
